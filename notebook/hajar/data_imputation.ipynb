{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation Methods\n",
    "\n",
    "Considering the number of missing values found within the dataset a variety of imputation methods were considered to take care of data sparsity. To address this, key features of the data set were considered including the fact that feetures are highly correlated in addition to whether the data is missing at random, missing completley at random, or missing not at random. \n",
    "\n",
    "Missing Completely at Random, MCAR, means there is no relationship between the missingness of the data and any values, observed or missing. Those missing data points are a random subset of the data. There is nothing systematic going on that makes some data more likely to be missing than others.\n",
    "\n",
    "Missing at Random, MAR, means there is a systematic relationship between the propensity of missing values and the observed data, but not the missing data. Whether an observation is missing has nothing to do with the missing values, but it does have to do with the values of an individualâ€™s observed variables. So, for example, if men are more likely to tell you their weight than women, weight is MAR.\n",
    "\n",
    "Missing Not at Random, MNAR, means there is a relationship between the propensity of a value to be missing and its values. This is a case where the people with the lowest education are missing on education or the sickest people are most likely to drop out of the study.\n",
    "\n",
    "### Potential Methods:\n",
    "1. Random Regression Imputation\n",
    "2. KNN imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Features with a substatntial amount of mising data\n",
    "\n",
    "First we assess columns with NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Match ID 18Char                                  0\n",
       "Completion Date                                147\n",
       "Match Support Contact Notes                   1454\n",
       "Stage                                            0\n",
       "Little ID                                        0\n",
       "                                             ...  \n",
       "Little Birthdate                                 0\n",
       "Little Mailing Address Census Block Group     8714\n",
       "Big Home Census Block Group                   9102\n",
       "Big Employer/School Census Block Group       37743\n",
       "Match Length                                     0\n",
       "Length: 68, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../data/Training.xlsx\")\n",
    "df.isna().sum() #count number of NaN values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Match ID 18Char                              39345\n",
       "Completion Date                              39198\n",
       "Match Support Contact Notes                  37891\n",
       "Stage                                        39345\n",
       "Little ID                                    39345\n",
       "                                             ...  \n",
       "Little Birthdate                             39345\n",
       "Little Mailing Address Census Block Group    30631\n",
       "Big Home Census Block Group                  30243\n",
       "Big Employer/School Census Block Group        1602\n",
       "Match Length                                 39345\n",
       "Length: 68, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() #count number of non-Nan values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Match ID 18Char                               0.000000\n",
       "Completion Date                               0.373618\n",
       "Match Support Contact Notes                   3.695514\n",
       "Stage                                         0.000000\n",
       "Little ID                                     0.000000\n",
       "                                               ...    \n",
       "Little Birthdate                              0.000000\n",
       "Little Mailing Address Census Block Group    22.147668\n",
       "Big Home Census Block Group                  23.133816\n",
       "Big Employer/School Census Block Group       95.928326\n",
       "Match Length                                  0.000000\n",
       "Length: 68, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the percent of missing values\n",
    "percent_missing = df.isnull().sum() * 100 / len(df) \n",
    "percent_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify features with the most amount of Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the distribution of non missing data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the Data is MCAR\n",
    "\n",
    "Firstly we identify if the data is MCAR to determine if case deletion is the best approach for handling the missing values.\n",
    "\n",
    "1. We compare the distribution of observations with missing values versus non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify observations with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distributions of missing and non missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We conduct Little's test for MCAR to identify if the data is MCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct little's test for MCAR\n",
    "from pyampute.exploration.mcar_statistical_tests import MCARTest\n",
    "mt = MCARTest(method=\"little\")\n",
    "# mt.little_mcar_test(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Regression Imputation\n",
    "\n",
    "Assumptions:\n",
    "- \n",
    "\n",
    "Steps:\n",
    "1.\n",
    "2.\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN imputation\n",
    "\n",
    "Assumptions:\n",
    "- \n",
    "\n",
    "Steps:\n",
    "1.\n",
    "2.\n",
    "3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
